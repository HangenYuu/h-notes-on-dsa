[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\nThis blog is mostly for my own study of data structures and algorithms and LeetCode questions. Therefore, it lacks the normal structure of a study resource for audience, especially for the LeetCode questions mentioned. There will be no problem statements, constraints, etc., only notes on intuition, approach, and code solutions with comments. Please open the corresponding LeetCode/LintCode questions while reading."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "H’s notes on Data Structuress and Algorithms",
    "section": "",
    "text": "Sliding window\n\n\n\n\n\nA variation of two pointers\n\n\n\n\n\n\nMar 17, 2023\n\n\nPham Nguyen Hung\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinary search\n\n\n\n\n\nBinary search\n\n\n\n\n\n\nMar 16, 2023\n\n\nPham Nguyen Hung\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStack\n\n\n\n\n\nStack\n\n\n\n\n\n\nMar 15, 2023\n\n\nPham Nguyen Hung\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTwo pointers\n\n\n\n\n\nTwo pointers\n\n\n\n\n\n\nMar 15, 2023\n\n\nPham Nguyen Hung\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\n\n\n\n\n\nArray\n\n\n\n\n\n\nMar 14, 2023\n\n\nPham Nguyen Hung\n\n\n\n\n\n\n  \n\n\n\n\nTree\n\n\n\n\n\nMostly binary tree\n\n\n\n\n\n\nMar 8, 2023\n\n\nPham Nguyen Hung\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinked List\n\n\n\n\n\nLinked List\n\n\n\n\n\n\nMar 7, 2023\n\n\nPham Nguyen Hung\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraph\n\n\n\n\n\nGraph\n\n\n\n\n\n\nFeb 10, 2023\n\n\nPham Nguyen Hung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/array/index.html",
    "href": "posts/array/index.html",
    "title": "Array",
    "section": "",
    "text": "Firstly, See About page."
  },
  {
    "objectID": "posts/array/index.html#definition",
    "href": "posts/array/index.html#definition",
    "title": "Array",
    "section": "Definition:",
    "text": "Definition:\nThe easiest, linear data structure, consisting of elements stored in contiguous memory slots. Elements are access by index, usually a number. The dictionary, or HashMap is a related data structure, consisting of key-value pairs that will be used in dealing array question."
  },
  {
    "objectID": "posts/array/index.html#problem",
    "href": "posts/array/index.html#problem",
    "title": "Array",
    "section": "Problem:",
    "text": "Problem:\n\n1. Two Sum:\nThe basic of basic problem, the first problem everybody encounters when he/she starts LeetCoding.\n\nIntuition\n\nTraversing the list seems like the most logical thing to do. The brute-force way is to check every pair of numbers. The time complexity is O(n^2). To optimize this, it is better to store the information we have already encountered when we traverse the list. We need to use a data structure that supports fast searching - HashMap. Either way works, but the HashMap can be used for storing the index of the element as well. If we store an element as the key and the index as the value, we can quickly search and return the indices.\n\n\nApproach\n\nThe algorithm can be described as:\n\nTraverse the array from the beginning.\nStore the element encountered in a set/dictionary.\nCheck if the sum - element is in the dictionary.\nReturn the indices.\n\n\n\nComplexity\n\nTime complexity:  \\(O(n)\\): Traversing the whole list once.\nSpace complexity:  \\(O(n)\\): In the worst case, we will have a dictionary with a size equal to the array.\n\n\n\nCode\nfrom collections import defaultdict\nclass Solution:\n    def twoSum(self, nums: List[int], target: int) -> List[int]:\n        numsDict = defaultdict(int)\n        for ind, num in enumerate(nums):\n            if target-num in numsDict:\n                return [ind, numsDict[target-num]]\n            numsDict[num] = ind\n\n\n\n2. Contains Duplicate\n\nIntuition\n\nAgain, traverse the array, storing information about what we have encountered. This time, we only need to store the element itself, so a HashSet suffices.\n\n\nApproach\n\n\nTraverse the array.\nCheck if the current element is in the HashSet. If it is, return True for duplicate.\nIf we reach the end of the array, return False for no duplicate.\n\n\n\nComplexity\n\nTime complexity:  \\(O(n)\\): Traversing the whole list once.\nSpace complexity:  \\(O(n)\\): In the worst case, we will have a set with a size equal to the array.\n\n\n\nCode\nclass Solution:\n    def containsDuplicate(self, nums: List[int]) -> bool:\n        numSet = set()\n        for num in nums:\n            if num in numSet:\n                return True\n            numSet.add(num)\n        return False\n\n\n\n3. Valid Anagram:\n\nIntuition\n\nAgain, traverse the array, storing information about what we have encountered. This time, we only need to store the element itself, so a HashSet suffices.\n\n\nApproach\n\n\nTraverse the array.\nCheck if the current element is in the HashSet. If it is, return True for duplicate.\nIf we reach the end of the array, return False for no duplicate.\n\n\n\nComplexity\n\nTime complexity:  \\(O(n)\\): Traversing the whole list once.\nSpace complexity:  \\(O(n)\\): In the worst case, we will have a set with a size equal to the array.\n\n\n\nCode\nfrom collections import defaultdict\nclass Solution:\n    def isAnagram(self, s: str, t: str) -> bool:\n        if len(s) != len(t):\n            return False\n        hashS, hashT = defaultdict(int), defaultdict(int)\n        for index in range(len(s)):\n            hashS[s[index]] += 1\n            hashT[t[index]] += 1\n        return hashS == hashT"
  },
  {
    "objectID": "posts/binary_search/index.html",
    "href": "posts/binary_search/index.html",
    "title": "Binary search",
    "section": "",
    "text": "Firstly, See About page."
  },
  {
    "objectID": "posts/binary_search/index.html#definitions",
    "href": "posts/binary_search/index.html#definitions",
    "title": "Binary search",
    "section": "Definitions:",
    "text": "Definitions:\nIn a sorted array, there exists a faster way to search for a specific element than visiting each element. The intuition is if we find an element that is smaller than expected, all of the elements before it are also smaller and can be discarded from the search and likewise if it is larger. The optimal way to take advantage of this property is striking in the middle every time, hence the name binary search."
  },
  {
    "objectID": "posts/binary_search/index.html#problem",
    "href": "posts/binary_search/index.html#problem",
    "title": "Binary search",
    "section": "Problem",
    "text": "Problem\n\n1. Binary serach\n\nIntuition\n\nThe basic problem of binary search. It basically asks you to implement it.\n\n\nApproach\n\n\nInitialize two pointers - start and end.\nTraverse the array from both ends.\nCalculate middle = (start + end)//2 and compare array[middle] with the target.\nIf we found the target, return middle. If we are smaller, move start to middle. If we are larger, move end to middle.\nIf we reach the end, return -1 as we do not find the target.\n\n\n\nComplexity\n\nTime complexity:  \\(O(logn)\\): We are cutting the array in half repeatedly, so it takes just \\(logn\\) to search.\nSpace complexity:  \\(O(1)\\): Pointers are essentially integers.\n\n\n\nCode\nclass Solution:\n    def search(self, nums: List[int], target: int) -> int:\n        # Edge case\n        if nums[0] > target or nums[-1] < target:\n            return -1\n        \n        # General case\n        if nums[0] == target:\n            return 0\n        if nums[-1] == target:\n            return len(nums) - 1\n        start, end = 0, len(nums) - 1\n        while start <= end:\n            mid = (start + end)//2\n            if nums[mid] == target:\n                return mid\n            elif nums[mid] < target:\n                start = mid + 1\n            else:\n                end = mid - 1\n        \n        return -1"
  },
  {
    "objectID": "posts/graph/index.html",
    "href": "posts/graph/index.html",
    "title": "Graph",
    "section": "",
    "text": "Firstly, See About page."
  },
  {
    "objectID": "posts/graph/index.html#definitions",
    "href": "posts/graph/index.html#definitions",
    "title": "Graph",
    "section": "Definitions:",
    "text": "Definitions:\n\nA nonlinear data structure consists of nodes connected by vertices.\nA graph can be undirected, directed, or weighted."
  },
  {
    "objectID": "posts/graph/index.html#disjoint-set",
    "href": "posts/graph/index.html#disjoint-set",
    "title": "Graph",
    "section": "Disjoint set:",
    "text": "Disjoint set:\nRepresented as a data structures in LeetCode’s terminology\nHelps to register the connectivity of a graph/network. Consists of two arrays:\n\nStore the node itself (represented by index)\nStore the parent/root vertex of the node\n\nThe problem of checking connectivity is reduced to the problem of checking whether two nodes have the same root node.\nThe disjoint set has two essential methods: find() and union(). find() : find the root node of a given vertex\n\nunion()\n\nunions two vertices and makes their root nodes the same\n\n\n\nInitialization:\n\nStart with creating an array with array[i]=i\nCan implement with emphasis on find() (Quick Find) or union() (Quick Union)\n\n\n\nQuick Find:\nInstead of storing the parent node, the array will store the root node straight-away. This makes for a quick find() but slower union() as we need to search the entire array.\n\n# UnionFind class\nclass UnionFind:\n    def __init__(self, size):\n        self.root = [i for i in range(size)]\n\n    def find(self, x):\n        return self.root[x]\n        \n    def union(self, x, y):\n        rootX = self.find(x)\n        rootY = self.find(y)\n        if rootX != rootY:\n            for i in range(len(self.root)):\n                if self.root[i] == rootY:\n                    self.root[i] = rootX\n\n    def connected(self, x, y):\n        return self.find(x) == self.find(y)\n\n\n# Test Case\nuf = UnionFind(10)\n# 1-2-5-6-7 3-8-9 4\nuf.union(1, 2)\nuf.union(2, 5)\nuf.union(5, 6)\nuf.union(6, 7)\nuf.union(3, 8)\nuf.union(8, 9)\nprint(uf.connected(1, 5))  # true\nprint(uf.connected(5, 7))  # true\nprint(uf.connected(4, 9))  # false\n# 1-2-5-6-7 3-8-9-4\nuf.union(9, 4)\nprint(uf.connected(4, 9))  # true\n\nTrue\nTrue\nFalse\nTrue\n\n\n\nTime Complexity:\n\n\n\n\nUnion-Find Constructor\nFind\nUnion\nConnected\n\n\n\n\nTime Complexity\n\\(O(N)\\)\n\\(O(1)\\)\n\\(O(N)\\)\n\\(O(1)\\)\n\n\n\nThe Union-Find Constructor is 1-liner in Python but it takes linear time to initialize in the system. #### Space Complexity: \\(O(N)\\) to store each node.\n\n\n\nQuick Union:\nunion() stops at setting the root node of the child to the root node of the parent only. find() and connected() will need to traverse more to find the answer. The worst-case time complexity for each operation swells to \\(O(N)\\), but the overall efficiency goes up.\n\n# UnionFind class\nclass UnionFind:\n    def __init__(self, size):\n        self.root = [i for i in range(size)]\n\n    def find(self, x):\n        while x != self.root[x]:\n            x = self.root[x]\n        return x\n        \n    def union(self, x, y):\n        rootX = self.find(x)\n        rootY = self.find(y)\n        if rootX != rootY:\n            self.root[rootY] = rootX\n\n    def connected(self, x, y):\n        return self.find(x) == self.find(y)\n\n\n# Test Case\nuf = UnionFind(10)\n# 1-2-5-6-7 3-8-9 4\nuf.union(1, 2)\nuf.union(2, 5)\nuf.union(5, 6)\nuf.union(6, 7)\nuf.union(3, 8)\nuf.union(8, 9)\nprint(uf.connected(1, 5))  # true\nprint(uf.connected(5, 7))  # true\nprint(uf.connected(4, 9))  # false\n# 1-2-5-6-7 3-8-9-4\nuf.union(9, 4)\nprint(uf.connected(4, 9))  # true\n\nTrue\nTrue\nFalse\nTrue\n\n\n\nTime Complexity:\n\n\n\n\nUnion-Find Constructor\nFind\nUnion\nConnected\n\n\n\n\nTime Complexity\n\\(O(N)\\)\n\\(O(N)\\)\n\\(O(N)\\)\n\\(O(N)\\)\n\n\n\nThe Union-Find Constructor is 1-liner in Python but it takes linear time to initialize in the system.\nNumber of operations to get to the root vertex will be H, where H is the height of the tree. In the worst case, H = N if the graph is a linked list.\n\n\nSpace Complexity:\n\\(O(N)\\) to store each node.\n\n\n\nOptimized Quick Union - Union by rank:\nFirst, observe that the smaller the height of the tree, the more efficient the algorithms run. So we will want to balance the tree as much as we can, but not to try too hard. One way to do so is union by rank. Rank here refers to the height of the vertex. When we union two vertices, instead of just picking the root node of one, we choose the root node of the vertex with a larger “rank”. We will merge the shorter tree under the taller tree and assign the root node of the taller tree as the root node for both vertices.\nThis is an optimization for Quick Union. To implement this, we need to make 2 changes:\n\nAdding an array rank to keep track of the rank of each vertex.\nModify the codes of union(). It is easy for the case of unequal rank. For the case of equal rank, we will assign one to the other (say, set root of Y to root of X) and increase the height of the other vertex (X’s height += 1).\n\n\n# UnionFind class\nclass UnionFind:\n    def __init__(self, size):\n        self.root = [i for i in range(size)]\n        self.rank = [1] * size\n\n    def find(self, x):\n        while x != self.root[x]:\n            x = self.root[x]\n        return x\n        \n    def union(self, x, y):\n        rootX = self.find(x)\n        rootY = self.find(y)\n        if rootX != rootY:\n            if self.rank[rootX] > self.rank[rootY]:\n                self.root[rootY] = rootX\n            elif self.rank[rootX] < self.rank[rootY]:\n                self.root[rootX] = rootY\n            else:\n                self.root[rootY] = rootX\n                self.rank[rootX] += 1\n\n    def connected(self, x, y):\n        return self.find(x) == self.find(y)\n\n\n# Test Case\nuf = UnionFind(10)\n# 1-2-5-6-7 3-8-9 4\nuf.union(1, 2)\nuf.union(2, 5)\nuf.union(5, 6)\nuf.union(6, 7)\nuf.union(3, 8)\nuf.union(8, 9)\nprint(uf.connected(1, 5))  # true\nprint(uf.connected(5, 7))  # true\nprint(uf.connected(4, 9))  # false\n# 1-2-5-6-7 3-8-9-4\nuf.union(9, 4)\nprint(uf.connected(4, 9))  # true\n\nTrue\nTrue\nFalse\nTrue\n\n\n\nTime Complexity:\n\n\n\n\nUnion-Find Constructor\nFind\nUnion\nConnected\n\n\n\n\nTime Complexity\n\\(O(N)\\)\n\\(O(logN)\\)\n\\(O(logN)\\)\n\\(O(logN)\\)\n\n\n\n\nThe Union-Find Constructor is 1-liner in Python but it takes linear time to initialize in the system.\nTree height will be at most log(N) + 1 when we repeatedly union components of equal rank, so find() will take O(logN) in the case.\nunion() and connected() depends on find(), so they need O(logN) as well.\n\n\n\nSpace Complexity:\n\\(O(N)\\) to store the value and the rank of each node.\n\n\n\nOptimized Quick Find - Path Compression:\nAfter finding the root node, we update the parent node of all traversed elements to their root node. We implement this with recursion.\n\n# UnionFind class\nclass UnionFind:\n    def __init__(self, size):\n        self.root = [i for i in range(size)]\n\n    def find(self, x):\n        if x == self.root[x]:\n            return x\n        self.root[x] = self.find(self.root[x])\n        return self.root[x]\n        \n    def union(self, x, y):\n        rootX = self.find(x)\n        rootY = self.find(y)\n        if rootX != rootY:\n            self.root[rootY] = rootX\n\n    def connected(self, x, y):\n        return self.find(x) == self.find(y)\n\n\n# Test Case\nuf = UnionFind(10)\n# 1-2-5-6-7 3-8-9 4\nuf.union(1, 2)\nuf.union(2, 5)\nuf.union(5, 6)\nuf.union(6, 7)\nuf.union(3, 8)\nuf.union(8, 9)\nprint(uf.connected(1, 5))  # true\nprint(uf.connected(5, 7))  # true\nprint(uf.connected(4, 9))  # false\n# 1-2-5-6-7 3-8-9-4\nuf.union(9, 4)\nprint(uf.connected(4, 9))  # true\n\nTrue\nTrue\nFalse\nTrue\n\n\n\nTime Complexity:\n\n\n\n\nUnion-Find Constructor\nFind\nUnion\nConnected\n\n\n\n\nTime Complexity\n\\(O(N)\\)\n\\(O(logN)\\)\n\\(O(logN)\\)\n\\(O(logN)\\)\n\n\n\n\nThe Union-Find Constructor is 1-liner in Python but it takes linear time to initialize in the system.\nThe worst-case call of find() will take O(N), but it will take O(1) afterwards. Average out, it takes O(logN) time to perform.\nunion() and connected() depends on find(), so they need O(logN) as well.\n\n\n\nSpace Complexity:\n\\(O(N)\\) to store the value and the rank of each node.\n\n\n\nFinal disjoint set with Path Compression and Union by Rank:\n\n# UnionFind class\nclass UnionFind:\n    def __init__(self, size) -> None:\n        \"\"\"\n        Function to initialize the UnionFind class\n\n        :param size: the number of nodes in the set\n        :return: None\n        \"\"\"\n        self.root = [i for i in range(size)]\n        self.rank = [1]*size\n    \n    def find(self, node):\n        \"\"\"\n        Function to return the root of a node. Recursively\n        modify the parent node if it is not yet the root\n\n        :param node: the node to search root for\\\n        :return: the root node\n        \"\"\"\n        if node == self.root[node]:\n            return node\n        # Parent node is not itself and possibly not the\n        # root node\n\n        # Set the root of node to the root of the parent node\n        # of node\n        self.root[node] = self.find(self.root[node])\n        return self.root[node]\n\n    def union(self, node1, node2):\n        root1 = self.find(node1)\n        root2 = self.find(node2)\n        # Do nothing if the two nodes are already connected\n        # Set the root of both nodes to the root of the node\n        # with heigher rank (height)\n        # In case of equal rank, set to the root of one node\n        # and increase the rank of that node\n        if root1 != root2:\n            if self.rank[root1] > self.rank[root2]:\n                self.root[root2] = root1\n            elif self.rank[root1] < self.rank[root2]:\n                self.root[root1] = root2\n            else:\n                self.root[root2] = root1\n                self.rank[root1] += 1\n    \n    def connected(self, node1, node2):\n        return self.find(node1) == self.find(node2)\n            \n\n# Test Case\nuf = UnionFind(10)\n# 1-2-5-6-7 3-8-9 4\nuf.union(1, 2)\nuf.union(2, 5)\nuf.union(5, 6)\nuf.union(6, 7)\nuf.union(3, 8)\nuf.union(8, 9)\nprint(uf.connected(1, 5))  # true\nprint(uf.connected(5, 7))  # true\nprint(uf.connected(4, 9))  # false\n# 1-2-5-6-7 3-8-9-4\nuf.union(9, 4)\nprint(uf.connected(4, 9))  # true\n\nTrue\nTrue\nFalse\nTrue\n\n\n\nTime Complexity:\n\n\n\n\n\n\n\n\n\n\n\nUnion-Find Constructor\nFind\nUnion\nConnected\n\n\n\n\nTime Complexity\n\\(O(N)\\)\n\\(O(\\alpha(N))\\)\n\\(O(\\alpha(N))\\)\n\\(O(\\alpha(N))\\)\n\n\n\n\\(\\alpha(N)\\) is the inverse Ackermann function, which is \\(O(1)\\) on average.\n\n\nSpace Complexity:\n\\(O(N)\\) to store the value and the rank of each node.\n\n\n\nProblems\n\n1. Number of provinces\nThe basic problem applying the disjoint set approach. A province is essentially a network, and two provinces are two disconnected networks. We just need to keep track of the number of provinces when we perform union.\n# UnionFind class\nclass UnionFind:\n    def __init__(self, size):\n        self.root = [i for i in range(size)]\n        # Use a rank array to record the height of each vertex, i.e., the \"rank\" of each vertex.\n        # The initial \"rank\" of each vertex is 1, because each of them is\n        # a standalone vertex with no connection to other vertices.\n        self.rank = [1] * size\n        self.count = size\n\n    # The find function here is the same as that in the disjoint set with path compression.\n    def find(self, x):\n        if x == self.root[x]:\n            return x\n        self.root[x] = self.find(self.root[x])\n        return self.root[x]\n\n    # The union function with union by rank\n    def union(self, x, y):\n        rootX = self.find(x)\n        rootY = self.find(y)\n        if rootX != rootY:\n            if self.rank[rootX] > self.rank[rootY]:\n                self.root[rootY] = rootX\n            elif self.rank[rootX] < self.rank[rootY]:\n                self.root[rootX] = rootY\n            else:\n                self.root[rootY] = rootX\n                self.rank[rootX] += 1\n            self.count -= 1\n\n    def getCount(self):\n        return self.count\n# The base problem for the whole class\n# Number of provinces are the number of disjoint sets left after performing all unions.\n# To achieve the goal, in addition to performing union-find, one also needs to take \n# care of the counting, which could be easily handled by deducting the number of nodes\n# after every union. \nclass Solution:\n    def findCircleNum(self, isConnected: list[list[int]]) -> int:\n        if not isConnected or len(isConnected) == 0:\n            return 0\n        n = len(isConnected)\n        uf = UnionFind(n)\n        for row in range(n):\n            for col in range(row + 1, n):\n                if isConnected[row][col] == 1:\n                    uf.union(row, col)\n        return uf.getCount()\n\n\n2. Number of Connected Components in an Undirected Graph\nEssentially the Number of Provinces problem. For this one, I tried not defining a separate UnionFind class but just the find() and union() functions.\nclass Solution:\n    def countComponents(self, n: int, edges: List[List[int]]) -> int:\n        rank = [1] * n\n        root = [i for i in range(n)]\n        \n        def find(x):\n            if x == root[x]:\n                return x\n            root[x] = find(root[x])\n            return root[x]\n        \n        def union(x, y):\n            # Declare n nonlocal to update n right in the union function\n            nonlocal n\n            rootX = find(x)\n            rootY = find(y)\n            if rootX != rootY:\n                if rank[rootX] > rank[rootY]:\n                    root[rootY] = rootX\n                elif rank[rootX] < rank[rootY]:\n                    root[rootX] = rootY\n                else:\n                    root[rootY] = rootX\n                    rank[rootX] += 1\n                n -= 1\n        \n        for edge in edges:\n            union(edge[0], edge[1])\n        \n        return n\n\n\n3. Graph Valid Tree\nA tree means that:\n\nNumber of edges provided must be at least the number of nodes - 1\nThere is no cycle.\n\nWe will use properties 1. to quickly rule out cases and 2. to implement the general algorithm. Property 2. is satisfied if we do not encounter two nodes with the same root when we perform the union operation; when we encounter such a case, we can return False immediately.\nclass Solution:\n    def validTree(self, n: int, edges: list[list[int]]) -> bool:\n        # write your code here\n        # Check the number of provinces\n        # False if more than 1\n        if len(edges) < n - 1:\n            return False\n        uf = UnionFind(n)\n        for A, B in edges:\n            if not uf.union(A, B):\n                return False\n        return True\n\n\n4. The Earliest Moment When Everyone Become Friends\nA.k.a the earliest moment the number of provinces goes to 1. If after performing all union operations, the number of provinces is larger than 1, we return -1\nfrom typing import List\n\nclass Solution:\n    def earliestAcq(self, logs: List[List[int]], n: int) -> int:\n        logs.sort()\n        root = [i for i in range(n)]\n        rank = [1] * n\n\n        def find(x):\n            if x == root[x]:\n                return x\n            root[x] = find(root[x])\n            return root[x]\n        \n        def union(x, y):\n            nonlocal n\n            rootX = find(x)\n            rootY = find(y)\n            if rootX != rootY:\n                if rank[rootX] > rank[rootY]:\n                    root[rootY] = rootX\n                elif rank[rootX] < rank[rootY]:\n                    root[rootX] = rootY\n                else:\n                    root[rootY] = rootX\n                    rank[rootX] += 1\n                n -= 1\n        \n        for timestamp, x, y in logs:\n            union(x, y)\n            if n == 1:\n                return timestamp\n                \n        return -1\n\n\n5. Smallest string with swaps:\nThe intuition here is recognizing that when the connected nindices form a graph that enable the corresponding characters to move around at will. THis means that we need to partition the indices into disjoint sets and sort within each set before joining them together to form the result.\nclass Solution:\n    def smallestStringWithSwaps(self, s: str, pairs: List[List[int]]) -> str:\n        length = component = len(s)\n        root = [i for i in range(length)]\n        rank = [1] * length\n\n        def find(x):\n            if x == root[x]:\n                return x\n            root[x] = find(root[x])\n            return root[x]\n        \n        def union(x, y):\n            nonlocal component\n            rootX = find(x)\n            rootY = find(y)\n            if rootX != rootY:\n                if rank[rootX] > rank[rootY]:\n                    root[rootY] = rootX\n                elif rank[rootX] < rank[rootY]:\n                    root[rootX] = rootY\n                else:\n                    root[rootY] = rootX\n                    rank[rootX] += 1\n                component -= 1\n        for pair in pairs:\n            union(pair[0], pair[1])\n        \n        # Easy case where every character is connected\n        if component == 1:\n            return ''.join(sorted(s))\n        \n        # General case\n        # We can only swap the the connected characters\n        listS = list(s)\n        copyListS = listS[:]\n        rootDict = {}\n        for i in range(length):\n            rootI = find(i)\n            if rootI in rootDict:\n                rootDict[rootI].append(i) # Ensure the nodes assoc. with a key is already sorted\n            else:\n                rootDict[rootI] = [i]\n\n        for connections in rootDict.values():\n            sortedConnections = sorted(connections, key = lambda x:ord(s[x]))\n            for i in range(len(connections)):\n                copyListS[connections[i]] = listS[sortedConnections[i]] \n        \n        return ''.join(copyListS)"
  },
  {
    "objectID": "posts/linked_list/index.html",
    "href": "posts/linked_list/index.html",
    "title": "Linked List",
    "section": "",
    "text": "Firstly, See About page."
  },
  {
    "objectID": "posts/linked_list/index.html#definitions",
    "href": "posts/linked_list/index.html#definitions",
    "title": "Linked List",
    "section": "Definitions:",
    "text": "Definitions:\n\nA nonlinear data structure consists of nodes with pointers to the next nodes.\nA linked list can be singly-linked, or doubly-linked, with just head pointer or together with tail pointer.\nFor LeetCode, a singly-linked list with head pointer is usually given.\n\nclass ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\nMay fall under many patterns, such as fast and slow pointers."
  },
  {
    "objectID": "posts/linked_list/index.html#general-trick",
    "href": "posts/linked_list/index.html#general-trick",
    "title": "Linked List",
    "section": "General trick:",
    "text": "General trick:\n\n1. Sentinel head (also tail):\nWe create a dummy head first, modify everything after, and then return the actual head with dummy.next\ndummy = ListNode(None)\nhead = dummy\n# Do a lot of stuff with head\nreturn dummy.next\nThis is useful as we can use the head as a pointer to traverse the linked list while still need to return the head of the linked list in result."
  },
  {
    "objectID": "posts/linked_list/index.html#problems",
    "href": "posts/linked_list/index.html#problems",
    "title": "Linked List",
    "section": "Problems:",
    "text": "Problems:\n\n1. Reverse Linked List\n\nIntuition\n\nThis is what I call a basic problem - a problem that can be become a sub-problem for a bigger task in the future LeetCode problems. This is like a formula that you have no choice but to remember (coding interview is still closed-book at the moment, year 2023), and then exploit it over and over again.\n\n\nApproach\n\nWhen dealing with Linked List, the king is pointer - something as dangerous as pointing gun to your headan object that points to the particular position of a node in the list. The number of pointers a problem requires depend on the amount of information we need at when processing each node in the list. Here, we need to know 3 pieces: the current node (obviously), the previous node to point the current node to, and the next node to move the pointer. Hence, we will use three pointers - pre, cur, and nex to keep track while traversing the list.\n\n\nComplexity\n\nTime complexity: \\(O(n)\\): Traversing the whole list once. \nSpace complexity: \\(O(1)\\): Pointers are essentially integers, taking constant memory \n\n\n\nCode\nclass Solution:\n    def reverseList(self, head: Optional[ListNode]) -> Optional[ListNode]:\n        # Easy case:\n        if head is None or head.next is None:\n            return head\n        \n        # General case:\n        pre, cur, nex = None, head, head.next\n        while nex:\n            cur.next = pre\n            pre = cur\n            cur = nex\n            nex = nex.next\n        cur.next = pre\n        return cur\n\n\n\n2. Merge Two Sorted Lists\nChoose a new linked list. Move the two head pointers down the two lists, compare the nodes, and splice them accordingly.\n\nIntuition\n\n\n\nApproach\n\n\n\nComplexity\n\nTime complexity: \nSpace complexity: \n\n\n\nCode\nclass Solution:\n    def mergeTwoLists(self, list1: Optional[ListNode], list2: Optional[ListNode]) -> Optional[ListNode]:\n        # Easy case\n        if list1 is None:\n            return list2\n        if list2 is None:\n            return list1\n        \n        # General case\n        # Most straightforward way is to create a new linked list\n        # Utilize the sentinel head trick here\n        dummy = ListNode()\n        head = dummy\n\n        # One list will reach the end before the other, so it is divided into 2 steps:\n        # 1. Compare and splice the nodes in the two list\n        # 2. Add the rest of one list to the end of the result.\n        while list1 and list2:\n            if list1.val <= list2.val:\n                head.next = list1\n                list1 = list1.next\n            else:\n                head.next = list2\n                list2 = list2.next\n            head = head.next\n        \n        if list1:\n            head.next = list1\n        elif list2:\n            head.next = list2\n        \n        return dummy.next\n\n\n\n3. Linked List Cycle\nThe introductory fast and slow pointers problem. Because there is a loop, the fast and slow pointers are bound to meet with each other somewhere.\n\nIntuition\n\n\n\nApproach\n\n\n\nComplexity\n\nTime complexity: \nSpace complexity: \n\n\n\nCode\nclass Solution:\n    def hasCycle(self, head: Optional[ListNode]) -> bool:\n        # Easy case\n        if head is None or head.next is None:\n            return False\n        \n        # General case\n        fast = slow = head\n        while fast.next and fast.next.next:\n            fast = fast.next.next\n            slow = slow.next\n            if fast == slow:\n                return True\n        return False\n\n\n\n4. Remove Nth Node From End of List\nThe idea is to initialize two fast and slow pointers, but started at different positions while moving at the same speed. We want that when the fast pointer hits the end, the slow pointer is at the node before the to-be-removed node to rearrange the connection.\n\nIntuition\n\n\n\nApproach\n\n\n\nComplexity\n\nTime complexity: \nSpace complexity: \n\n\n\nCode\nclass Solution:\n    def removeNthFromEnd(self, head: Optional[ListNode], n: int) -> Optional[ListNode]:\n        # Easy case\n        if head.next is None:\n            return\n        \n        # General case\n        # Fast and slow pointer\n        slow = fast = head\n        for _ in range(n+1):\n            if fast:\n                fast = fast.next\n            else:\n            # If fast pointer is already None before the end, there is just one\n            # case and it is the head needs removing, so we return the next element\n                return head.next\n        # If not, we start to move the slow and fast pointers to the end.\n        while fast:\n            slow, fast = slow.next, fast.next\n        \n        slow.next = slow.next.next\n        \n        return head\n\n\n\n5. Reorder List\nThe task can be divided into 3 parts:\n\nDivide the original list into 2.\nReverse the second half.\nMerge the two halves.\n\nHere we saw for the first time all the problems above come together into one problem. Here you see that I turned the second part into another hidden method within the Solution class. This is one way to do it. Another is to define the function within the function (nested function), which you will see many Python LeetCoders do. These two methods are equivalent in solving LeetCode problems. For outside world, I think that my current method is more appreciated, as of here.\n\nIntuition\n\n\n\nApproach\n\n\n\nComplexity\n\nTime complexity: \nSpace complexity: \n\n\n\nCode\nclass Solution:\n    def _reverseList(self, head: ListNode):\n        pre, cur, nex = None, head, head.next\n        while nex:\n            cur.next = pre\n            pre = cur\n            cur = nex\n            nex = nex.next\n        cur.next = pre\n        return cur\n    def reorderList(self, head: Optional[ListNode]) -> None:\n        \"\"\"\n        Do not return anything, modify head in-place instead.\n        \"\"\"\n        # Easy case:\n        if head.next is None or head.next.next is None:\n            return\n        \n        # General case:\n        fast = slow = temp1 = temp2 = head\n        while fast.next and fast.next.next:\n            fast = fast.next.next\n            slow = slow.next\n        temp2 = slow.next\n        slow.next = None\n        del slow, fast\n        temp2 = self._reverseList(temp2)\n        nex1, nex2 = temp1.next, temp2.next\n        while nex2:\n            temp1.next = temp2\n            temp2.next = nex1\n            temp1, temp2 = nex1, nex2\n            nex1, nex2 = nex1.next, nex2.next\n        temp1.next = temp2\n        if nex1:\n            temp2.next = nex1\n\n\n\n6. Find the Duplicate Number\nThis is not a Linked List question, but it utilizes the fast and slow pointers to turn it into a linked list question in the subtlest way possible. As noted in the editorial, this is similar to Linked List Cycle II. In the original one, fast and slow pointer is used to detect the cycle. Now the objective is to return the cycle entrance. Fast and slow pointers can be proved mathematically to work for that problem, by having the fast pointer starts at the intersection and the slow pointer starts at the start, they will meet each other at the entrance!\n\nIntuition\n\n\n\nApproach\n\n\n\nComplexity\n\nTime complexity: \nSpace complexity: \n\n\n\nCode\nclass Solution:\n    def findDuplicate(self, nums: List[int]) -> int:\n        # Phase 1: Intersection point\n        fast = slow = nums[0]\n        while True:\n            fast = nums[nums[fast]]\n            slow = nums[slow]\n            if fast == slow:\n                break\n        \n        # Phase 2: Find the cycle entrance\n        slow = nums[0]\n        while slow != fast:\n            fast = nums[fast]\n            slow = nums[slow]\n        \n        return slow\n\n\n\n7. Copy List with Random Pointer\nSometimes overthinking is a big problem. This question is super hard - if you try to do it in one go. The secret is to not do so. You do it in 2 passes. And use a HashMap to keep track of the copy.\n\nIntuition\n\n\n\nApproach\n\n\n\nComplexity\n\nTime complexity: \nSpace complexity: \n\n\n\nCode\n\"\"\"\n# Definition for a Node.\nclass Node:\n    def __init__(self, x: int, next: 'Node' = None, random: 'Node' = None):\n        self.val = int(x)\n        self.next = next\n        self.random = random\n\"\"\"\n\nclass Solution:\n    def copyRandomList(self, head: 'Optional[Node]') -> 'Optional[Node]':\n        # The first key in the dictionary to deal with the pointer to \n        # None of a node.\n        oldToCopy = {None: None}\n\n        # 1st pass: Create all the nodes only\n        cur = head\n        while cur:\n            oldToCopy[cur] = Node(cur.val)\n            cur = cur.next\n        \n        # 2nd pass: Create the links within the list\n        cur = head\n        while cur:\n            copy = oldToCopy[cur]\n            copy.next = oldToCopy[cur.next]\n            copy.random = oldToCopy[cur.random]\n            cur = cur.next\n        \n        return oldToCopy[head]\n\n\n\n8. Palindrome Linked List\nHere we see the reverse linked list sub-problem becomes relevant again. The algorithm is:\n\nGo to the middle of the linked list and divide it in 2 halves.\nReverse the second half.\nCheck each pair of nodes of two halves and return result.\n\n\nIntuition\n\n\n\nApproach\n\n\n\nComplexity\n\nTime complexity: \nSpace complexity: \n\n\n\nCode\nclass Solution:\n    def _reverseList(self, head: Optional[ListNode]) -> Optional[ListNode]:\n        pre, cur, nex = None, head, head.next\n        while nex:\n            cur.next = pre\n            pre = cur\n            cur = nex\n            nex = nex.next\n        cur.next = pre\n        return cur\n\n    def isPalindrome(self, head: Optional[ListNode]) -> bool:\n        # Easy case:\n        if head is None or head.next is None:\n            return True\n        \n        # General case:\n        slow, fast = head, head.next\n        while fast.next and fast.next.next:\n            slow = slow.next\n            fast = fast.next.next\n        if not fast.next:\n            temp = slow.next\n            slow.next = None\n        else:\n            temp = slow.next.next\n            slow.next.next = None\n        temp = self._reverseList(temp)\n        while temp:\n            if temp.val != head.val:\n                return False\n            temp, head = temp.next, head.next\n        return True\n\n\n\n9. Add Two Numbers\nThe second problem added to LeetCode, after Two Sum. The digits are arranged in reverse order, which makes it easier to add them. The algorithm can be represented as:\n\nWhile both heads not yet hit the end, traverse and add each pair of digit (remember to log the remaining).\nWhen a head hits the end, check if the remaining list has any node left and add them to the result.\n\n\nIntuition\n\n\n\nApproach\n\n\n\nComplexity\n\nTime complexity: \nSpace complexity: \n\n\n\nCode\n# Definition for singly-linked list.\n# class ListNode:\n#     def __init__(self, val=0, next=None):\n#         self.val = val\n#         self.next = next\nclass Solution:\n    def addTwoNumbers(self, l1: Optional[ListNode], l2: Optional[ListNode]) -> Optional[ListNode]:\n        dummy = ListNode()\n        head = dummy\n        remain = 0\n        while l1 and l2:\n            raw_sum = l1.val + l2.val + remain\n            remain = raw_sum // 10\n            temp_sum = raw_sum % 10\n            head.next = ListNode(temp_sum)\n            head = head.next\n            l1, l2 = l1.next, l2.next\n        \n        while l1:\n            if remain == 0:\n                head.next = l1\n                break\n            raw_sum = l1.val + remain\n            remain = raw_sum // 10\n            temp_sum = raw_sum % 10\n            head.next = ListNode(temp_sum)\n            head = head.next\n            l1 = l1.next\n        \n        while l2:\n            if remain == 0:\n                head.next = l2\n                break\n            raw_sum = l2.val + remain\n            remain = raw_sum // 10\n            temp_sum = raw_sum % 10\n            head.next = ListNode(temp_sum)\n            head = head.next\n            l2 = l2.next\n        if remain != 0:\n            head.next = ListNode(remain)\n        return dummy.next\n\n\n\n10. LRU Cache\n\nIntuition\n\n\n\nApproach\n\n\n\nComplexity\n\nTime complexity: \nSpace complexity: \n\n\n\nCode"
  },
  {
    "objectID": "posts/sliding_window/index.html",
    "href": "posts/sliding_window/index.html",
    "title": "Sliding window",
    "section": "",
    "text": "Firstly, See About page."
  },
  {
    "objectID": "posts/sliding_window/index.html#definitions",
    "href": "posts/sliding_window/index.html#definitions",
    "title": "Sliding window",
    "section": "Definitions",
    "text": "Definitions\nSliding window at its core is processing the data in an array in chunk, with limits set by 2 pointers at both sides. Sliding window is particularly suitable if we need to performf repeated operations on a sub-array. Instead of going crazy over all of the possible chunks, we can just change the result (e.g. sum of elements in the window) by discarding the leaving and accounting for the entering element(s)."
  },
  {
    "objectID": "posts/sliding_window/index.html#problems",
    "href": "posts/sliding_window/index.html#problems",
    "title": "Sliding window",
    "section": "Problems",
    "text": "Problems\n\n1. Best Time to Buy and Sell Stock\n\nIntuition\n\nThe first problem in sliding window. The brute-force way of doing this is to check every single pair fo number for the largest right-left pair. The time complexity will be \\(O(n^2)\\). How do we modify this solution to be easier?\nFirst, the brute-force algorithm involves keeping track of the maximum number so far. This is a good thing that we can keep.\nSecond, let’s assume this array of [2, ..., 1]. Let’s say that the maximum of the subarray between 2 and 1 is 6: [2, ...6..., 1] (it does not matter where the 6 is as long as it occurs before 1). The max profit we can get so far is \\(6-2=4\\). To increase the profit, there are two ways: shift the buy date to a day with smaller price, or shift the sell date to a day with a larger price. Let’s say there is a 7 after 1. We can increase the profit if we shift the sell date from 6 to 7: [2, ...6..., 1, ...7...]. However, the best profit is when we shift the buy date from 2 to 1 as well. Now, because we already keep track of the max profit so far, so it cannot be worse if we shift the buy date every single time we find a better buy date.\n\n\nApproach\n\nThe algorithm: 1. Initialize the left and right sides of the window + the max profit so far. 2. Traverse the array with the right side. 3. If we encounter a better buy date (right < left), update the buy date. If we encounter a potential sell date (right >= left), check and update the profit so far. 4. Return the max profit at the end. #### Complexity - Time complexity:  \\(O(n)\\): We are traversing the array once. - Space complexity:  \\(O(1)\\): We are only keeping track of a bunch of integers. #### Code\nclass Solution:\n    def maxProfit(self, prices: List[int]) -> int:\n        buyDay = maxProfit = 0\n        for sellDay in range(len(prices)):\n            if prices[sellDay] < prices[buyDay]:\n                buyDay = sellDay\n            else:\n                currentProfit = prices[sellDay] - prices[buyDay]\n                if currentProfit > maxProfit:\n                    maxProfit = currentProfit\n        return maxProfit"
  },
  {
    "objectID": "posts/stack/index.html",
    "href": "posts/stack/index.html",
    "title": "Stack",
    "section": "",
    "text": "Firstly, See About page."
  },
  {
    "objectID": "posts/stack/index.html#definitions",
    "href": "posts/stack/index.html#definitions",
    "title": "Stack",
    "section": "Definitions:",
    "text": "Definitions:\nA data structure with the trademark of LIFO (last in, first out). It has direct analogy to the list in Python, and we actually will use the built-in list as the stack. There are alternatives to have a stack (such as queue.LifoQueue), but normally, a python list suffices."
  },
  {
    "objectID": "posts/stack/index.html#problems",
    "href": "posts/stack/index.html#problems",
    "title": "Stack",
    "section": "Problems:",
    "text": "Problems:\n\n1. Valid Parentheses\n\nIntuition\n\nThis is the Two Sum of stack. The problem requirements can be translated into the intuition that if we push the left parenthesis into a stack and pop them out whenever we encounter a right parenthesis, the correct parenthesis sequence will generate all matching pairs.\n\n\nApproach\n\n\nInitialize, including a HashMap for right and left parenthesis, and check that the array has an even number of elements.\nTraverse the array of parentheses.\nIf we encounter a left parenthesis, push it to a stack.\nIf we encounter a right parenthesis, compare it to the one we pop from the stack. If they do not match, return False immediately.\nAt the end, return True if the stack is empty, else False.\n\n\n\nComplexity\n\nTime complexity:  \\(O(n)\\): Traversing the whole array once.\nSpace complexity:  \\(O(n)\\): At the worst case, we will need to store half of the array inside the stack.\n\n\n\nCode\nclass Solution:\n    def isValid(self, s: str) -> bool:\n        if len(s) % 2:\n            return False\n        stack = []\n        parenthesisDict = {'{':'}', '[':']', '(':')'}\n        for parenthesis in s:\n            if parenthesis in parenthesisDict:\n                stack.append(parenthesis)\n            else:\n                if len(stack) == 0 or parenthesis != parenthesisDict[stack.pop()]:\n                    return False\n        return len(stack) == 0\n\n\n\n2."
  },
  {
    "objectID": "posts/tree/index.html",
    "href": "posts/tree/index.html",
    "title": "Tree",
    "section": "",
    "text": "Firstly, See About page."
  },
  {
    "objectID": "posts/tree/index.html#definitions",
    "href": "posts/tree/index.html#definitions",
    "title": "Tree",
    "section": "Definitions",
    "text": "Definitions\nThe upgraded version of a linked list.\n\nIt is acyclic (doesn’t contain any cycles);\nThere exists a path from the root to any node;\nHas \\(N - 1\\) edges, where \\(N\\) is the number of nodes in the tree; and\nEach node has exactly one parent node with the exception of the root node.\n\nFor binary tree, all nodes have at most 2 children.\n# Definition for a binary tree node.\nclass TreeNode:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\n\n\n\n\n\n\nTerms\nMeaning\n\n\n\n\nNode & Edges\nTrivia\n\n\nRoot\nThe first node\n\n\nLeaf node\nNode with no child\n\n\nInternal node\nNode with at least one child\n\n\nAncestor\nNodes that are between the pathfrom the root to the current root. Including the node itself\n\n\nDescendent\nNodes that are between the pathfrom the root to the current root. Including the node itself\n\n\nLevel\nNumber of ancestors from that nodeuntil the root node. Start at 0 or 1, go down.\n\n\nHeight\nNumber of edges on the longest path fromthat node to a leaf. Start at 0, go up.\n\n\nDepth\nNumber of edges on the path from rootto that node. Start at 0, go down."
  },
  {
    "objectID": "posts/tree/index.html#categories",
    "href": "posts/tree/index.html#categories",
    "title": "Tree",
    "section": "Categories",
    "text": "Categories\n\nFull binary tree\n\nEvery node has 0 or 2 children.\n\nComplete binary tree\n\nAll levels are completely filled except possibly the last level. All nodes are as far left as possible.\n\nPerfect binary tree\n\nAll internal nodes have two children and all leaf nodes have the same level\n\nBalanced binary tree\n\nEvery node fulfil the condition: height difference of the left and right subtree of the node is not more than than 1. Searching, insertion, and deletion in a balanced binary tree takes \\(O(logn)\\) instead of \\(O(n)\\) in an unbalanced binary tree."
  },
  {
    "objectID": "posts/tree/index.html#notes",
    "href": "posts/tree/index.html#notes",
    "title": "Tree",
    "section": "Notes:",
    "text": "Notes:\n\n1. Depth-first search\nDepth-first search is the first heavily used technique. It is essentially pre-order traversal of a tree. All traversal types are given here:\nclass TreeNode:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\n    def pre_order_traversal(self, root: TreeNode):\n        if root is not None:\n            print(root.val)\n            pre_order_traversal(root.left)\n            pre_order_traversal(root.right)\n\n    def in_order_traversal(self, root: TreeNode):\n        if root is not None:\n            in_order_traversal(root.left)\n            print(root.val)\n            in_order_traversal(root.right)\n    \n    def post_order_traversal(self, root: TreeNode):\n        if root is not None:\n            post_order_traversal(root.left)\n            post_order_traversal(root.right)\n            print(root.val)\nDepth-first search is often implemented in recursion. In thinking in recursion, the most important thing is visualization of the call stack.\nIn thinking in recursion, one must forget the whole picture and start thinking about each node. For each node, decide how the information there should be processed, then recurse on the children. When you are a node, the only thing you know are 1. node value and 2. how to get to children. The recursive function should manipulate these things.\nIn defining the recursive functions, there are two things to decide when we define:\n\nreturn value - the value the child passes to the parent. For example, for the max depth problem this is the max depth for the current node’s subtree.\nstate - the value the parent passes to the child. For example, to know if the current node’s value is larger than its parent we have to maintain the parent’s value as a state.\n\nAnother way to solve the problem is to replace return value with a global variable."
  },
  {
    "objectID": "posts/tree/index.html#problems",
    "href": "posts/tree/index.html#problems",
    "title": "Tree",
    "section": "Problems",
    "text": "Problems\n\n1. Same Tree\nThe first application of recursion. Thinking in node, the two are the same if each pair of nodes has the same value. Therefore, the recursive function should 1. check the current pair then 2. check the two child pairs. This problem is simple enough so that we don’t need to write another helper function to deal with the situation.\n\nIntuition\n\n\n\nApproach\n\n\n\nComplexity\n\nTime complexity: \nSpace complexity: \n\n\n\nCode\nclass Solution:\n    def isSameTree(self, p: Optional[TreeNode], q: Optional[TreeNode]) -> bool:\n        if not p and not q:\n            return True\n        if p and q:\n            return (p.val==q.val and\n                    self.isSameTree(p.left, q.left) and\n                    self.isSameTree(p.right, q.right))\n        return False\nHowever, this problem is not just depth-first search. Breadth-first search can be used as well, as in the iterative solution.\nfrom collections import deque\nclass Solution:\n    def isSameTree(self, p, q):\n        def check(p, q):\n            # if both are None\n            if not p and not q:\n                return True\n            # one of p and q is None\n            if not q or not p:\n                return False\n            if p.val != q.val:\n                return False\n            return True\n        \n        deq = deque([(p, q),])\n        while deq:\n            p, q = deq.popleft()\n            if not check(p, q):\n                return False\n            \n            if p:\n                deq.append((p.left, q.left))\n                deq.append((p.right, q.right))\n                    \n        return True\n\n\n\n2. Flip Equivalent Binary Trees\nThe tweaked problem of above. The trees now are the same if each pair of nodes are the same and each pair of corresponding children are the sae or each pair of flipped children are the same. This means adding a case in the return.\n\nIntuition\n\n\n\nApproach\n\n\n\nComplexity\n\nTime complexity: \nSpace complexity: \n\n\n\nCode\nclass Solution:\n    def flipEquiv(self, root1: Optional[TreeNode], root2: Optional[TreeNode]) -> bool:\n        if not root1 and not root2:\n            return True\n        if root1 and root2:\n            return (root1.val==root2.val and\n                    ((self.flipEquiv(root1.left, root2.left) and\n                    self.flipEquiv(root1.right, root2.right)) or\n                    (self.flipEquiv(root1.left, root2.right) and\n                    self.flipEquiv(root1.right, root2.left))))\n        return False\n\n\n\n3. Maximum Depth of Binary Tree\n\nIntuition\n\nIt is easier if we have a picture.\n\nLet’s think recursively about the problem. Let’s say we start with an empty tree. The height will immediately be 0. If we have a tree with just 1 node, the depth should be 1. Now suppose that node is a child of another node. This node will have two 2 children: the aforementioned node and an empty node. The depth of the empty child should be 0 while the depth of the non-empty child is 1. Ultimately, the depth of the root node will be 2. By imagining this for an increasingly bigger tree, we can see that the depth of a node is the maximum depth of its child node plus 1. In the recursion framework, the return value is the depth a node, which we pass up from the child to the parent. #### Approach  In terms of recursive algorithm, we have to define the base case - return 0 if the root is empty. Afterwards, we just need to call the fuction recursively.\n\n\nComplexity\nWith \\(n\\) the number of tree nodes:\n\nTime complexity:  \\(O(n)\\): We have a traverse every node in the tree.\nSpace complexity:  \\(O(log(n))\\): This is the average height of the recursive call stack. In the worst case of a total unbalance tree where all nodes are grouped to 1 side, the space complexity is \\(O(n)\\).\n\n\n\nCode\nclass Solution:\n    def maxDepth(self, root: Optional[TreeNode]) -> int:\n        if root is None:\n            return 0\n        \n        return 1 + max(self.maxDepth(root.left), self.maxDepth(root.right))"
  },
  {
    "objectID": "posts/two_pointers/index.html",
    "href": "posts/two_pointers/index.html",
    "title": "Two pointers",
    "section": "",
    "text": "Firstly, See About page."
  },
  {
    "objectID": "posts/two_pointers/index.html#definitions",
    "href": "posts/two_pointers/index.html#definitions",
    "title": "Two pointers",
    "section": "Definitions:",
    "text": "Definitions:\nThis is not a data structure, but a pattern of coding interview questions. This is something passed down from languages with pointers such as C++ or Java. The idea is that we will traverse the array in both direction. This operation has use in some problems, particularly palindrome checking."
  },
  {
    "objectID": "posts/two_pointers/index.html#problem",
    "href": "posts/two_pointers/index.html#problem",
    "title": "Two pointers",
    "section": "Problem",
    "text": "Problem\n\n1. Valid Palindrome\n\nIntuition\n\nThe basic problem of two pointers. The problem can be solved by many ways (strip the string then reverse, etc.), but the most straightforward way if you know two pointers is using two pointers. You will traverse the string in both directions, bypassing non-alphanumeric characters. For each alphanumeric pairs, the lowercase versions of the character must match.\n\n\nApproach\n\n\nInitialize two pointers.\nTraverse the array from both ends.\nFor both pointers, if we encounter a non-alphanumeric characters, we increment or decrement further.\nIf we encounter a differing pair, return False immediately.\nAt the end, return True if the right end (or the left end, depending on which pointer is moved first) has moved, else False (this is to resolve edge cases suchas \".,\").\n\n\n\nComplexity\n\nTime complexity:  \\(O(n)\\): Traversing the whole array once.\nSpace complexity:  \\(O(1)\\): Pointers are essentially integers.\n\n\n\nCode\nclass Solution:\n    def isPalindrome(self, s: str) -> bool:\n        # Edge case\n        if len(s) < 2:\n            return True\n\n        # General case\n        leftPointer, rightPointer = 0, len(s) - 1\n        while leftPointer <= rightPointer:\n            while (leftPointer < rightPointer) and (not s[leftPointer].isalnum()):\n                leftPointer += 1\n            while (leftPointer < rightPointer) and (not s[rightPointer].isalnum()):\n                rightPointer -= 1\n            \n            if s[leftPointer].lower() != s[rightPointer].lower():\n                return False\n            leftPointer += 1\n            rightPointer -= 1\n        \n        return rightPointer < len(s) - 1"
  }
]